Filtered_Informed = dropFirst(filtered_informed$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape for plotting
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1) +
scale_color_manual(
values = c("red", "blue", "orange", "darkgreen"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash", "solid"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
labs(title = "Nile River Flow: Kalman Filtering and Smoothing",
y = "Flow (10^8 m³)", x = "Year") +
theme_minimal() +
theme(legend.title = element_blank())
# Display plot
print(p)
# Compare the filtered results from both initializations
diff_init_effect <- mean(abs(data_plot$Filtered_Diffuse - data_plot$Filtered_Informed), na.rm = TRUE)
cat("Mean absolute difference between diffuse and informed filtering: ",
round(diff_init_effect, 4), "\n")
# Load libraries
library(dlm)
library(ggplot2)
library(reshape2)
# Set working directory (optional for RStudio users)
if (requireNamespace("rstudioapi", quietly = TRUE)) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# Load built-in Nile River dataset
data("Nile")
y <- as.numeric(Nile)
N <- length(y)
# Model-building function for the local level model
build_model <- function(theta) {
dlmModPoly(order = 1, dV = exp(theta[1]), dW = exp(theta[2]))
}
# MLE estimation of model parameters using full data
init_theta <- log(c(var(y), var(y) / 10))
fit <- dlmMLE(y, parm = init_theta, build = build_model)
fitted_model <- build_model(fit$par)
# Kalman filter and smoother with default (diffuse) initialization
filtered_diffuse <- dlmFilter(y, fitted_model)
smoothed <- dlmSmooth(filtered_diffuse)
# Informed initialization (tight prior on the first state)
informed_model <- fitted_model
informed_model$m0 <- mean(y)
informed_model$C0 <- 0.01
filtered_informed <- dlmFilter(y, informed_model)
# Prepare data for plotting
data_plot <- data.frame(
Time = time(Nile),
Observed = y,
Filtered_Diffuse = dropFirst(filtered_diffuse$m),
Filtered_Informed = dropFirst(filtered_informed$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape for plotting
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1) +
scale_color_manual(
values = c("red", "blue", "orange", "darkgreen"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash", "solid"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
labs(title = "Nile River Flow: Kalman Filtering and Smoothing",
y = "Flow (10^8 m³)", x = "Year") +
theme_minimal() +
theme(legend.title = element_blank())
# Display plot
print(p)
# Compare the filtered results from both initializations
diff_init_effect <- mean(abs(data_plot$Filtered_Diffuse - data_plot$Filtered_Informed), na.rm = TRUE)
cat("Mean absolute difference between diffuse and informed filtering: ",
round(diff_init_effect, 4), "\n")
# Load libraries
library(dlm)
library(ggplot2)
library(reshape2)
# Set working directory (optional for RStudio users)
if (requireNamespace("rstudioapi", quietly = TRUE)) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# Load built-in Nile River dataset
data("Nile")
y <- as.numeric(Nile)
N <- length(y)
# Model-building function for the local level model
build_model <- function(theta) {
dlmModPoly(order = 1, dV = exp(theta[1]), dW = exp(theta[2]))
}
# MLE estimation of model parameters using full data
init_theta <- log(c(var(y), var(y) / 10))
fit <- dlmMLE(y, parm = init_theta, build = build_model)
fitted_model <- build_model(fit$par)
# Kalman filter and smoother with default (diffuse) initialization
filtered_diffuse <- dlmFilter(y, fitted_model)
smoothed <- dlmSmooth(filtered_diffuse)
# Informed initialization (tight prior on the first state)
informed_model <- fitted_model
informed_model$m0 <- mean(y)
informed_model$C0 <- 0.01
filtered_informed <- dlmFilter(y, informed_model)
# Prepare data for plotting
data_plot <- data.frame(
Time = time(Nile),
Observed = y,
Filtered_Diffuse = dropFirst(filtered_diffuse$m),
Filtered_Informed = dropFirst(filtered_informed$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape for plotting
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1) +
scale_color_manual(
values = c("red", "blue", "orange", "darkgreen"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash", "solid"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
labs(title = "Nile River Flow: Kalman Filtering and Smoothing",
y = "Flow (10^8 m³)", x = "Year") +
theme_minimal() +
theme(legend.title = element_blank())
# Display plot
print(p)
# Compare the filtered results from both initializations
diff_init_effect <- mean(abs(data_plot$Filtered_Diffuse - data_plot$Filtered_Informed), na.rm = TRUE)
cat("Mean absolute difference between diffuse and informed filtering: ",
round(diff_init_effect, 4), "\n")
# Load libraries
library(dlm)
library(ggplot2)
library(reshape2)
# Set working directory (optional for RStudio users)
if (requireNamespace("rstudioapi", quietly = TRUE)) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# Load built-in Nile River dataset
data("Nile")
y <- as.numeric(Nile)
N <- length(y)
# Model-building function for the local level model
build_model <- function(theta) {
dlmModPoly(order = 1, dV = exp(theta[1]), dW = exp(theta[2]))
}
# MLE estimation of model parameters using full data
init_theta <- log(c(var(y), var(y) / 10))
fit <- dlmMLE(y, parm = init_theta, build = build_model)
fitted_model <- build_model(fit$par)
# Kalman filter and smoother with default (diffuse) initialization
filtered_diffuse <- dlmFilter(y, fitted_model)
smoothed <- dlmSmooth(filtered_diffuse)
# Informed initialization (tight prior on the first state)
informed_model <- fitted_model
informed_model$m0 <- mean(y)
informed_model$C0 <- 0.01
filtered_informed <- dlmFilter(y, informed_model)
# Prepare data for plotting
data_plot <- data.frame(
Time = time(Nile),
Observed = y,
Filtered_Diffuse = dropFirst(filtered_diffuse$m),
Filtered_Informed = dropFirst(filtered_informed$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape for plotting
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1) +
scale_color_manual(
values = c("red", "blue", "orange", "darkgreen"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash", "solid"),
labels = c("Observed", "Filtered (Diffuse)", "Filtered (Informed)", "Smoothed")
) +
labs(title = "Nile River Flow: Kalman Filtering and Smoothing",
y = "Flow (10^8 m³)", x = "Year") +
theme_minimal() +
theme(legend.title = element_blank())
# Display plot
print(p)
ggsave(filename = "nile_kalman_plot.png", plot = p, width = 10, height = 6, dpi = 300)
# Compare the filtered results from both initializations
diff_init_effect <- mean(abs(data_plot$Filtered_Diffuse - data_plot$Filtered_Informed), na.rm = TRUE)
cat("Mean absolute difference between diffuse and informed filtering: ",
round(diff_init_effect, 4), "\n")
# Load necessary libraries
library(fredr)
library(dlm)
library(ggplot2)
library(reshape2)
# Set working directory (optional for RStudio users)
if (requireNamespace("rstudioapi", quietly = TRUE)) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# Set your FRED API key
# Replace 'your_api_key_here' with your actual FRED API key
# fredr_set_key("your_api_key_here")
fredr_set_key("6954169ffff382d9f9f69d89322206d8")
# Define the time range for data retrieval
start_date <- as.Date("1990-01-01")
end_date <- as.Date("2024-12-31")
# Retrieve U.S. Real GDP data (GDPC1: Real Gross Domestic Product, billions of chained 2012 dollars)
us_gdp_data <- fredr(
series_id = "GDPC1",
observation_start = start_date,
observation_end = end_date,
frequency = "q"
)
# Retrieve U.K. Nominal GDP data (UKNGDP: Gross Domestic Product for United Kingdom, millions of pounds)
uk_gdp_data <- fredr(
series_id = "UKNGDP",
observation_start = start_date,
observation_end = end_date,
frequency = "q"
)
# Function to apply local level model and perform Kalman filtering and smoothing
apply_kalman <- function(data, country_name) {
y <- data$value
time <- data$date
N <- length(y)
# Define the local level model
build_model <- function(theta) {
dlmModPoly(order = 1, dV = exp(theta[1]), dW = exp(theta[2]))
}
# Initial parameter estimates
init_theta <- log(c(var(y), var(y) / 10))
# Maximum Likelihood Estimation
fit <- dlmMLE(y, parm = init_theta, build = build_model)
fitted_model <- build_model(fit$par)
# Kalman filtering and smoothing
filtered <- dlmFilter(y, fitted_model)
smoothed <- dlmSmooth(filtered)
# Prepare data for plotting
data_plot <- data.frame(
Time = time,
Observed = y,
Filtered = dropFirst(filtered$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape data for ggplot
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1) +
scale_color_manual(
values = c("red", "blue", "darkgreen"),
labels = c("Observed", "Filtered", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash"),
labels = c("Observed", "Filtered", "Smoothed")
) +
labs(title = paste(country_name, "GDP: Kalman Filtering and Smoothing"),
y = "GDP",
x = "Year") +
theme_minimal() +
theme(legend.title = element_blank())
# Save plot
ggsave(filename = paste0(tolower(country_name), "_gdp_kalman_plot.png"), plot = p, width = 10, height = 6)
# Display plot
print(p)
}
# Apply Kalman filtering and smoothing to U.S. GDP data
apply_kalman(us_gdp_data, "U.S.")
# Apply Kalman filtering and smoothing to U.K. GDP data
apply_kalman(uk_gdp_data, "U.K.")
# Load necessary libraries
library(fredr)
library(dlm)
library(ggplot2)
library(reshape2)
# Set your FRED API key
fredr_set_key("6954169ffff382d9f9f69d89322206d8")
# Define the time range for the last decade
start_date <- as.Date("2014-01-01")
end_date <- as.Date("2024-12-31")
# Retrieve U.K. Nominal GDP data
uk_gdp_data <- fredr(
series_id = "UKNGDP",
observation_start = start_date,
observation_end = end_date,
frequency = "q"
)
# Function to apply local level model and perform Kalman filtering and smoothing
apply_kalman <- function(data, country_name) {
y <- data$value
time <- data$date
N <- length(y)
# Define a custom local level model with higher process noise to enhance curve separation
build_model <- function(theta) {
dlmModPoly(order = 1, dV = exp(theta[1]), dW = exp(theta[2]))
}
# Initial parameter estimates: slightly less variance on observation noise
init_theta <- log(c(var(y) / 5, var(y) / 2))
# Maximum Likelihood Estimation
fit <- dlmMLE(y, parm = init_theta, build = build_model)
fitted_model <- build_model(fit$par)
# Kalman filtering and smoothing
filtered <- dlmFilter(y, fitted_model)
smoothed <- dlmSmooth(filtered)
# Prepare data for plotting
data_plot <- data.frame(
Time = time,
Observed = y,
Filtered = dropFirst(filtered$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape data for ggplot
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1.1) +
scale_color_manual(
values = c("red", "blue", "darkgreen"),
labels = c("Observed", "Filtered", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash"),
labels = c("Observed", "Filtered", "Smoothed")
) +
labs(title = paste(country_name, "GDP (2014–2024): Kalman Filtering and Smoothing"),
y = "GDP (Millions of £)",
x = "Year") +
theme_minimal() +
theme(legend.title = element_blank(),
plot.title = element_text(hjust = 0.5, size = 14))
# Save plot
ggsave(filename = paste0(tolower(gsub("\\.", "", country_name)), "_gdp_kalman_plot.png"),
plot = p, width = 10, height = 6)
# Display plot
print(p)
}
# Apply Kalman filtering and smoothing to U.K. GDP data only
apply_kalman(uk_gdp_data, "U.K.")
library(fredr)
library(dlm)
library(ggplot2)
library(reshape2)
# Set FRED API key
fredr_set_key("6954169ffff382d9f9f69d89322206d8")
# Define time range: last decade
start_date <- as.Date("2014-01-01")
end_date <- as.Date("2024-12-31")
# Retrieve UK nominal GDP data
uk_gdp_data <- fredr(
series_id = "UKNGDP",
observation_start = start_date,
observation_end = end_date,
frequency = "q"
)
# Function to apply Kalman filtering and smoothing with fixed variances
apply_kalman <- function(data, country_name) {
y <- data$value
time <- data$date
# Force higher variance: increase process noise to allow more deviation
obs_var <- var(y) * 0.05  # relatively small observation noise
state_var <- var(y) * 0.5  # larger process noise to smooth more
# Build the local level model with fixed variances
model <- dlmModPoly(order = 1, dV = obs_var, dW = state_var)
# Kalman filter and smoother
filtered <- dlmFilter(y, model)
smoothed <- dlmSmooth(filtered)
# Prepare data for plotting
data_plot <- data.frame(
Time = time,
Observed = y,
Filtered = dropFirst(filtered$m),
Smoothed = dropFirst(smoothed$s)
)
# Reshape data for plotting
plot_data <- melt(data_plot, id.vars = "Time")
# Plot
p <- ggplot(plot_data, aes(x = Time, y = value, color = variable, linetype = variable)) +
geom_line(size = 1.1) +
scale_color_manual(
values = c("red", "blue", "darkgreen"),
labels = c("Observed", "Filtered", "Smoothed")
) +
scale_linetype_manual(
values = c("solid", "dashed", "dotdash"),
labels = c("Observed", "Filtered", "Smoothed")
) +
labs(title = paste(country_name, "GDP (2014–2024): Kalman Filtering and Smoothing"),
y = "GDP (Millions of £)",
x = "Year") +
theme_minimal() +
theme(legend.title = element_blank(),
plot.title = element_text(hjust = 0.5, size = 14))
# Save plot
ggsave(filename = paste0(tolower(gsub("\\.", "", country_name)), "_gdp_kalman_plot.png"),
plot = p, width = 10, height = 6)
print(p)
}
# Run for UK GDP
apply_kalman(uk_gdp_data, "U.K.")
# ======================
# C-CAPM GMM Estimation
# ======================
# Load necessary libraries
library(gmm)
library(quantmod)
library(fredr)
library(zoo)
library(xts)
# Set your FRED API key
fredr_set_key("6954169ffff382d9f9f69d89322206d8")
# Set working directory (optional for RStudio users)
if (requireNamespace("rstudioapi", quietly = TRUE)) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# -----------------------------
# Step 1: Download Economic Data
# -----------------------------
# Real Personal Consumption Expenditures
consumption <- fredr(
series_id = "PCECC96",
observation_start = as.Date("2000-01-01")
)
# 3-Month Treasury Bill rate (risk-free rate)
rf <- fredr(
series_id = "TB3MS",
observation_start = as.Date("2000-01-01")
)
# Convert to xts and process
cons_xts <- xts(consumption$value, order.by = consumption$date)
rf_xts <- xts(rf$value / 100 / 12, order.by = rf$date)  # convert annual % to monthly decimal
colnames(cons_xts) <- "consumption"
colnames(rf_xts) <- "rf"
# -----------------------------
# Step 2: Download Financial Data
# -----------------------------
# S&P 500 index from Yahoo Finance
getSymbols("^GSPC", src = "yahoo", from = "2000-01-01", periodicity = "monthly")
sp500_returns <- monthlyReturn(Cl(GSPC))
colnames(sp500_returns) <- "r_m"
# -----------------------------
# Step 3: Prepare and Merge Data
# -----------------------------
# Merge all series
data <- merge.xts(cons_xts, rf_xts, sp500_returns, join = "inner")
data <- na.omit(data)
# Compute log consumption growth and excess returns
data$dc <- diff(log(data$consumption))
data$rx <- lag(data$r_m - data$rf, k = -1)  # lead excess return
# ======================
# C-CAPM GMM Estimation
# ======================
# Load necessary libraries
library(gmm)
library(quantmod)
library(fredr)
library(zoo)
library(xts)
# Set your FRED API key
fredr_set_key("6954169ffff382d9f9f69d89322206d8")
# Set working directory (optional for RStudio users)
if (requireNamespace("rstudioapi", quietly = TRUE)) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
}
# -----------------------------
# Step 1: Download Economic Data
# -----------------------------
# Real Personal Consumption Expenditures
consumption <- fredr(
series_id = "PCECC96",
observation_start = as.Date("2000-01-01")
)
# 3-Month Treasury Bill rate (risk-free rate)
rf <- fredr(
series_id = "TB3MS",
observation_start = as.Date("2000-01-01")
)
# Convert to xts and process
cons_xts <- xts(consumption$value, order.by = consumption$date)
rf_xts <- xts(rf$value / 100 / 12, order.by = rf$date)  # convert annual % to monthly decimal
colnames(cons_xts) <- "consumption"
colnames(rf_xts) <- "rf"
# -----------------------------
# Step 2: Download Financial Data
# -----------------------------
# S&P 500 index from Yahoo Finance
getSymbols("^GSPC", src = "yahoo", from = "2000-01-01", periodicity = "monthly")
sp500_returns <- monthlyReturn(Cl(GSPC))
colnames(sp500_returns) <- "r_m"
# -----------------------------
# Step 3: Prepare and Merge Data
# -----------------------------
# Merge all series
data <- merge.xts(cons_xts, rf_xts, sp500_returns, join = "inner")
data <- na.omit(data)
# Compute log consumption growth and excess returns
data$dc <- diff(log(data$consumption))
data$rx <- lag(data$r_m - data$rf, k = -1)  # lead excess return
